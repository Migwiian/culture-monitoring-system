{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c89181ca-b8a3-454b-a20d-53cf61d1bc6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "20782caf-9616-40c7-8dc4-f9ae77ca0eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c873d8c0-0f37-44d7-8551-b208ad3711f1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['firm', 'date_review', 'job_title', 'current', 'location', 'overall_rating', 'work_life_balance', 'culture_values', 'diversity_inclusion', 'career_opp', 'comp_benefits', 'senior_mgmt', 'recommend', 'ceo_approv', 'outlook', 'headline', 'pros', 'cons']\n"
     ]
    }
   ],
   "source": [
    "df_check = pd.read_csv('../../data/raw/glassdoor_reviews.csv', nrows=10)\n",
    "\n",
    "print(df_check.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e7ebdbe3-19d8-469a-b075-3760ca54b8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_raw_data(input_path: Path):\n",
    "    \"\"\"\n",
    "    Performs schema validation on the raw input file.\n",
    "\n",
    "    Args:\n",
    "        input_path (Path): The file path to the raw CSV data.\n",
    "\n",
    "    Raises:\n",
    "        FileNotFoundError: If the raw data file does not exist.\n",
    "        ValueError: If the dataset is missing columns required for VoluntÄs scoring.\n",
    "    \"\"\"\n",
    "    if not input_path.exists():\n",
    "        logger.error(f\"File not found: {input_path}\")\n",
    "        raise FileNotFoundError(f\"Missing raw data file at {input_path}\")\n",
    "\n",
    "    # Load sample to minimize memory footprint during validation\n",
    "    df_sample = pd.read_csv(input_path, nrows=100)\n",
    "    \n",
    "    # These columns are the 'vital signs' of our methodology\n",
    "    required_cols = [\n",
    "        'culture_values', 'work_life_balance', \n",
    "        'senior_mgmt', 'career_opp', 'diversity_inclusion'\n",
    "    ]\n",
    "    \n",
    "    missing = [col for col in required_cols if col not in df_sample.columns]\n",
    "    \n",
    "    if missing:\n",
    "        logger.error(f\"Schema mismatch. Missing: {missing}\")\n",
    "        raise ValueError(f\"Input data is missing required pillars: {missing}\")\n",
    "    \n",
    "    logger.info(\"âœ… Schema validation successful.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "97a3221c-90e7-4053-ae72-7919d28668c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_raw_data(input_path: Path):\n",
    "    \"\"\"\n",
    "    Performs schema validation on the raw input file.\n",
    "\n",
    "    Args:\n",
    "        input_path (Path): The file path to the raw CSV data.\n",
    "\n",
    "    Raises:\n",
    "        FileNotFoundError: If the raw data file does not exist.\n",
    "        ValueError: If the dataset is missing columns required for VoluntÄs scoring.\n",
    "    \"\"\"\n",
    "    if not input_path.exists():\n",
    "        logger.error(f\"File not found: {input_path}\")\n",
    "        raise FileNotFoundError(f\"Missing raw data file at {input_path}\")\n",
    "\n",
    "    # Load sample to minimize memory footprint during validation\n",
    "    df_sample = pd.read_csv(input_path, nrows=100)\n",
    "    \n",
    "    # These columns are the 'vital signs' of our methodology\n",
    "    required_cols = [\n",
    "        'culture_values', 'work_life_balance', \n",
    "        'senior_mgmt', 'career_opp', 'diversity_inclusion'\n",
    "    ]\n",
    "    \n",
    "    missing = [col for col in required_cols if col not in df_sample.columns]\n",
    "    \n",
    "    if missing:\n",
    "        logger.error(f\"Schema mismatch. Missing: {missing}\")\n",
    "        raise ValueError(f\"Input data is missing required pillars: {missing}\")\n",
    "    \n",
    "    logger.info(\"âœ… Schema validation successful.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8f84128f-1be7-465a-a2af-8f2873631942",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Cleans data and engineers features based on VoluntÄs Culture Pillars.\n",
    "\n",
    "    This function performs the following transformations:\n",
    "    1. Removes records missing the overall rating.\n",
    "    2. Maps raw ratings to 'Purpose', 'Growth', and 'Belonging' scores.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The raw glassdoor reviews dataframe.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A processed dataframe with VoluntÄs-aligned features.\n",
    "    \"\"\"\n",
    "    logger.info(\"ðŸ—ï¸ Starting feature engineering on 850k records...\")\n",
    "\n",
    "    # Data Quality: Only keep reviews that provide a clear signal\n",
    "    df = df.dropna(subset=['overall_rating'])\n",
    "\n",
    "    # --- PILLAR 1: PURPOSE ---\n",
    "    # Direct mapping of cultural values to the Purpose pillar\n",
    "    df['purpose_score'] = df['culture_values']\n",
    "\n",
    "    # --- PILLAR 2: BELONGING ---\n",
    "    # Belonging is calculated as the mean of inclusivity and balance.\n",
    "    # Formula: $$Belonging = \\frac{WLB + SeniorMgmt + DiversityInclusion}{3}$$\n",
    "    belonging_cols = ['work_life_balance', 'senior_mgmt', 'diversity_inclusion']\n",
    "    df['belonging_score'] = df[belonging_cols].mean(axis=1)\n",
    "\n",
    "    # --- PILLAR 3: GROWTH ---\n",
    "    # Maps career opportunities directly to the Growth pillar\n",
    "    df['growth_score'] = df['career_opp']\n",
    "\n",
    "    logger.info(f\"âœ¨ Feature engineering complete. Processed {len(df)} rows.\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1f23f2d7-a2a1-4fa5-9e81-fc91c289bd32",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '__file__' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[33;03mMain execution block for the data pipeline.\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# 1. PATH RESOLUTION\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# This ensures the script runs correctly regardless of where it is called from.\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# It finds the root folder by going up 3 levels from /src/data/make_dataset.py\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m PROJECT_ROOT = Path(\u001b[34;43m__file__\u001b[39;49m).resolve().parent.parent.parent\n\u001b[32m      9\u001b[39m RAW_DATA_PATH = PROJECT_ROOT / \u001b[33m\"\u001b[39m\u001b[33mdata\u001b[39m\u001b[33m\"\u001b[39m / \u001b[33m\"\u001b[39m\u001b[33mraw\u001b[39m\u001b[33m\"\u001b[39m / \u001b[33m\"\u001b[39m\u001b[33mglassdoor_reviews.csv\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     10\u001b[39m PROCESSED_DATA_PATH = PROJECT_ROOT / \u001b[33m\"\u001b[39m\u001b[33mdata\u001b[39m\u001b[33m\"\u001b[39m / \u001b[33m\"\u001b[39m\u001b[33mprocessed\u001b[39m\u001b[33m\"\u001b[39m / \u001b[33m\"\u001b[39m\u001b[33mculture_intelligence_v1.parquet\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mNameError\u001b[39m: name '__file__' is not defined"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \"\"\"\n",
    "    Main execution block for the data pipeline.\n",
    "    \"\"\"\n",
    "    # 1. PATH RESOLUTION\n",
    "    # This ensures the script runs correctly regardless of where it is called from.\n",
    "    # It finds the root folder by going up 3 levels from /src/data/make_dataset.py\n",
    "    PROJECT_ROOT = Path(__file__).resolve().parent.parent.parent\n",
    "    RAW_DATA_PATH = PROJECT_ROOT / \"data\" / \"raw\" / \"glassdoor_reviews.csv\"\n",
    "    PROCESSED_DATA_PATH = PROJECT_ROOT / \"data\" / \"processed\" / \"culture_intelligence_v1.parquet\"\n",
    "\n",
    "    # Create the output directory if it doesn't exist\n",
    "    PROCESSED_DATA_PATH.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    try:\n",
    "        # 2. RUN PIPELINE\n",
    "        validate_raw_data(RAW_DATA_PATH)\n",
    "\n",
    "        logger.info(\"Loading raw dataset (this may take a moment)...\")\n",
    "        # Optimization: We load only the columns we need to save RAM\n",
    "        df_raw = pd.read_csv(RAW_DATA_PATH)\n",
    "\n",
    "        df_processed = clean_data(df_raw)\n",
    "\n",
    "        # 3. EXPORT AS PARQUET\n",
    "        # Parquet is used for high-performance reading in later ML stages.\n",
    "        df_processed.to_parquet(PROCESSED_DATA_PATH, index=False)\n",
    "        logger.info(f\"ðŸ’¾ Processed data archived at: {PROCESSED_DATA_PATH}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Pipeline failed: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a4bb74-a2da-4c40-b212-bced31d34552",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
